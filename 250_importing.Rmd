
<!-- This file by Martin Monkman 
is licensed under a Creative Commons Attribution 4.0 International License
https://creativecommons.org/licenses/by/4.0/  

Some of it comes straight from Hadley Wickham & Garrett Grolemund's book _R for Data Science_, found online here: https://r4ds.had.co.nz/

It also uses great swaths of content from the tidyverse reference material for {readr} and {readxl}, by RStudio. 
You can find that material here: 
https://readr.tidyverse.org/index.html 
https://readxl.tidyverse.org/index.html -->


# Importing {#importing}


## Reading

Hadley Wickham and Garrett Grolemund, _R for Data Science_, 2nd ed.

* [8. Data import](https://r4ds.hadley.nz/data-import)


J.D. Long and Paul Teetor, [R Cookbook (2nd ed.)](https://rc2e.com/inputandoutput)

* [4. Input and Output](https://rc2e.com/inputandoutput)


## Getting started

For this hands-on exercise, we will be loading the data contained in a CSV file. Base R has the ability to read CSV files with the `read.csv()` function, but we'll be using the `read_csv()` function, which is in the {readr} package. This package loads when we run `library(tidyverse)`.  

We will also be loading the contents of an Excel file. While the {readxl} package is part of the tidyverse, it is not part of the core that loads with `library(tidyverse)`: we have to run the `library()` function separately.

## Setup

This chunk of R code loads the packages that we will be using.


```{r setup_250, eval=FALSE}
library(tidyverse)  # we will be using the functions of {readr}
library(readxl)     

library(gapminder)

```



## Reading a CSV file

CSV files are very commonly used for storing flat files. They don't have any formattingâ€”just the number or text in the cell.

The package {readr} is designed to make importing these files simple.


(This example comes straight from https://readr.tidyverse.org/index.html)

Run this chunk to create an object called `mtcars`, from a CSV file of the same name.

```{r}
# example
mtcars <- read_csv("mtcars.csv")

```

You'll see that the console displays the type that has been assigned to each variable. In this case, they are all of the type "double", which is a numeric type (think numbers with decimals or exponents; not integers).

Adding the `cols()` argument allows us to alter what {readr} has decided for us. For example, we could set the `cyl` variable to be an integer.

```{r}
# example
mtcars <- read_csv("mtcars.csv",
                   col_types =
                     cols(cyl = col_integer()))
```



Insert an R chunk and rerun the example above, but with the `am` variable also set to integer and `gear` set to character.

```{r}
# solution
read_csv("mtcars.csv",
         col_types = 
           cols(cyl = col_integer(),
                am = col_integer(),
                gear = col_character())
)

```




The {readr} package allows a lot of control over how the file is read. Of particular utility are 

* `na = ""` -- specify which values you want to be turned into `NA`

* `skip = 0` -- specify how many rows to skip 

* `n_max = Inf` -- the maximum number of records to read



Read the first 5 rows of the "mtcars.csv" file.

```{r}
# solution
read_csv("mtcars.csv", 
         n_max = 5)



```


In some instances, we may wish to read a sub-set of rows in the middle of our file, and retain the headers. In this code below, we do just that.

The first line uses the `names()` function to read the variable names, and assign them to an object that we can use in the subsequent `read_csv()` function.

```{r}
# set the column names
mtcars_col_names <- names(read_csv("mtcars.csv", n_max = 0))

# read file starting at 5th row, adding column names
read_csv("mtcars.csv", 
         col_names = mtcars_col_names, 
         skip = 5, 
         n_max = 10)
```



## Reading an Excel file

If anything, Excel files are more common than CSV and other plain-text data files. They seem to multiply like coat hangers in the closet...

And as we see in the article by Karl Broman & Kara Woo, ["Data Organization in Spreadsheets"](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989), the features of Excel files can encourage some ways of storing information that makes it hard for us to analyze. Excel files can also contain a wide variety of data format types. {readxl} tries to figure out what's going on, but like {readr}, it allows you to override some of those automatic decisions.


In this example, our Excel file is in a different directory, one below our current directory, called "data". Working with file paths like this, we can import the contents of data files and worksheets that are anywhere on our computer, the local network, or the internet.

```{r}
deaths <- read_excel("data/deaths.xlsx")
deaths
```

What do you notice about the "Date of birth" and "Date of death" columns?



Read in the "deaths" file, but use the `range = ` option to specify when to start reading the file:


```{r}
# Example
deaths <- read_excel("data/deaths.xlsx", 
                     range = "A1:B3")

deaths

# solution
deaths <- read_excel(
  "data/deaths.xlsx", sheet = "arts", 
  range = "A5:F15"
)

deaths

```


Use the `skip =` and `n_max =` options to achieve the same thing:

```{r}

# solution
deaths <- read_excel(
  "data/deaths.xlsx",
  skip = 4,
  n_max = 10
)

deaths


```



If we know how many rows to skip at the top, and how many to omit at the bottom, we can insert a calculation as to what our `n_max()` value needs to be. This would be useful in the circumstance where we have multiple sheets we need to read, each having the same structure with a fixed number of header and footer rows that do not contain relevant data, but the number of rows in between varies.

In the case of the "deaths.xlsx" file, we have four rows of junk data at the top (prior to the variable names), and another four rows at the bottom. By subtracting those numbers from the total count of rows in the file, we have the object `valid_rows` that we can apply as the value for the `n_max = ` in our `read_excel()` function.

```{r}
# first, read the data file
deaths <- read_excel("data/deaths.xlsx")
# determine the total number of rows in the sheet
rowcount <- nrow(deaths)

# calculate the number of rows with relevant data "rowcount2"
valid_rows <- rowcount - 4 - 4   # 4 rows of junk data at the top after the header, 4 rows of junk data at the bottom

read_excel("data/deaths.xlsx",
           skip = 4,
           n_max = valid_rows)

```

For more information on reading areas of an Excel sheet, see this article at the {readxl} site: https://readxl.tidyverse.org/articles/sheet-geometry.html



Excel files often (almost always?) have multiple sheets in them. It's possible to specify which one you want to use with the `sheets = ""` option. You can also use the position number (if you happen to know it). 

Note that if you don't specify the sheet, {readxl} will default to the first one.

The `excel_sheets()` function will tell you the name of the sheets in an Excel file.

```{r}
datasets <- "data/datasets.xlsx"

excel_sheets(datasets)

# Example
read_excel(datasets, "iris")

```

Now, read in the "mtcars" sheet using the name of the sheet.


```{r}

# Solution
read_excel(datasets, "mtcars")

```

And finally, read in the "quakes" sheet, using the position.

```{r}
# Solution
read_excel(datasets, 4)

```

***

Methods for saving dataframes will be introduced [later in the course, in the "Exporting data & graphics" chapter](#exporting).

***

## Exercise

### Discussion

The Excel portion of this chapter relies on some common methods to deal with how spreadsheet files are often used (Excel isn't the only spreadsheet software, just very common.) Read the journal article by Karl Broman & Kara Woo, ["Data Organization in Spreadsheets"](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989)[@Broman_Woo_2017] and come to class ready to discuss the following questions.


**Discussion questions:**

1. How many people in your discussion group have used spreadsheets, in their research, courses, or at home?

2. How many people in your discussion group have accidentally done something that made them frustrated or sad? How many of them have done the sorts of things that Broman and Woo advise against?

3. What are basic principles for using spreadsheets for good data organization?

4. What are good approaches for handling dates in spreadsheets?


***

## Reference Material


{readr} 
https://readr.tidyverse.org/

{readxl}
https://readxl.tidyverse.org/index.html




