---
title: "Classic Rock 25 - sales data"
output: html_notebook
---

As I embarked on teaching [Data Analytics Coding Fundamentals](https://martinmonkman.com/courses/bida302_2019/) at the University of Victoria's Continuing Studies department, I started to search for good example data sets to use. There are many already available, including R packages or open data sites. The course is part of the [Business Intelligence and Data Analytics] (https://continuingstudies.uvic.ca/business-technology-and-public-relations/series/business-intelligence-and-data-analytics) series, so in addition to gentle introductions that are referenced in [_R for Data Science_](https://r4ds.had.co.nz/) (like `mtcars` in [{datasets}](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html) [{Lahman}](https://cran.r-project.org/web/packages/Lahman/index.html)) I wanted a dataset that was typical of what you might encounter in a business situation. My search for such a dataset came up empty...the tables used as examples in business courses are often summary tables that have already been wrangled. The students in a data coding course need to learn how to _create_ those tables from the ground up. So I decided to create a synthetic dataset that presents a variety of data wrangling challenges, as well as some interesting analytic opportunities.

I cast my memory back 30 years, to a time when I was working for a wholesale company that distributed LPs, cassettes, and those new-fangled compact discs to a wide range of retailers. A table showing the details of each store's orders would do the trick...a single year's worth of order data from a handful of stores would be adequate, and could then be linked to other tables about the stores. It could also be expanded to include additional years (with some trends embedded), inventory management, and customer relationship management (CRM).

The fictional wholesale company, CR25 (for "Classic Rock 25") only sells 25 album titles. They are the biggest selling / most famous albums by the 25 most-played artists shown in Walt Hickey's article [Why Classic Rock Isnâ€™t What It Used To Be](https://fivethirtyeight.com/features/why-classic-rock-isnt-what-it-used-to-be/) (FiveThirtyEight, 2014-07-07). 


### Setup

The first step is to install the necessary packages. I also set the seed to [a number associated with a classic rock staple](https://www.youtube.com/watch?v=axLRUszuu9I), so that future runs of the code will generate the same data table. This is important, as some of the lessons in the course were based on summary tables drawn from the master file.

```{r setup}
# tidyverse packages
library(dplyr)
library(readr)
library(lubridate)
library(ggplot2)
#
# utilities
set.seed(8675309)

```


### Input data

To create the album list, I created a csv file with the artist and percentage of all plays fields, using the table in the article (which is displayed as an image; note that there appears to be an error in the table, in that Boston has a lower rank but a higher percentage than Queen or Journey). I also added a representative album by that artist--I used some judgement here. The album is the biggest selling, most famous, and/or the one with the most hit singles that the artist made. I also opted for a "no compilations" rule; one could make the case that, as one example, The Rolling Stones might be better or more accurately represented by _Hot Rocks_. 

I also added a price field; albums released before 1976 are \$7.98, [those released 1976-1981 are $8.98](https://en.wikipedia.org/wiki/Hard_Promises#History), and 1982 and beyond are \$9.98. The sole exception to this is Pink Floyd's double album _The Wall_, which I priced at \$14.98.

```{r}

albumlist <- read_csv("classic_rock_25_538.csv")
albumlist

```


The next step was to create a csv file with some fictional stores. What I did here was use the names of Canadian chains that are now defunct record retailers that were active in the 70s and 80s. You can find them listed in the [Wikipedia List of defunct Canadian companies](https://en.wikipedia.org/wiki/List_of_defunct_Canadian_companies#Consumer_retail,_including_grocery) I left off HMV, as it was an international brand that was late to the market.

I also assigned each one to one of four regions (based on the cardinal points of the compass), and gave them a store ID number.

```{r}
storelist <- read_csv("storelist.csv")

storelist

storelist %>%
  group_by(chain, region) %>%
  tally()

storelist %>%
  group_by(region) %>%
  tally()

storelist %>%
  group_by(chain) %>%
  tally()

  
```

## Create order

### order date

https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html

```{r}
jan01 <- ymd("2019-01-01")
startdate <- as_date(floor_date(jan01, "year"))
enddate <- as_date(ceiling_date(jan01, "year") - days(1))
daterange <- tibble(orderdate = as_date(c(startdate:enddate)))

orderdate_fun <- function(){ 
daterange %>%
  sample_n(1) %>%
  pull(orderdate) 
}  

# set the size of the order based on year quarter
# - same number of orders but biggest in 4th quarter, smallest in 1st
# - value sets the mean value of poisson distribution from which random value is pulled
order_mean_fun <- function(orderdate){
  order_qtr <- quarter(orderdate)
  order_mean <- case_when(
    order_qtr == 1 ~ 4,
    order_qtr == 4 ~ 6,
    TRUE ~ 5
  )
}
```


```{r}
# function to randomly select the store
store_fun <- function(){ 
storelist %>%
  sample_n(1) %>%
  pull(store.id) 
}  

```



### album_order_fun

```{r}
album_order_fun <- function(...){
  sample_n(albumlist, 1, weight = pct_plays) %>%
    select(artist, album, price) %>%
  mutate(format = sample(c("lp", "cass"), 1, prob = c(0.33, 0.67)),
         qty = rpois(1, 4)
  )
}
```


### multiples

```{r}
# TEST
n = rpois(1, 7)
order_final <- data.frame(artist = as.character(),
                          album = as.character(),
                          price = as.double(),
                          format = as.character(),
                          qty = as.integer(),
                          stringsAsFactors = FALSE)  

for(i in 1:n){
  order_final[i, ] <- album_order_fun()
}

order_final
```

test orderdate and order_mean 

```{r}
orderdate <- orderdate_fun()
orderdate
order_mean <- order_mean_fun(orderdate)
order_mean
```

```{r}
order_fun_1 <- function(){
  n = rpois(1, 5)
  order_final <- data.frame(artist = as.character(),
                          album = as.character(),
                          price = as.double(),
                          format = as.character(),
                          qty = as.integer(),
                          stringsAsFactors = FALSE)  
  
  for(i in 1:n){
    order_final[i, ] <- album_order_fun()
  }
  order_final
  }


#TEST 
order_fun_1()
```


```{r}
# now with order date and store id appended after the run

order_fun <- function(){
  
  orderdate <- orderdate_fun()

# conditional on store open date being before random order date  
  orderstore.id <- store_fun()
  
  store.opendate <- storelist %>%
    filter(store.id == orderstore.id) %>%
    pull(open_date)

  if(store.opendate < orderdate){

    order_mean <- order_mean_fun(orderdate)
    n = rpois(1, order_mean)
  

  # define blank form  
  order_final <- data.frame(artist = as.character(),
                          album = as.character(),
                          price = as.double(),
                          format = as.character(),
                          qty = as.integer(),
                          stringsAsFactors = FALSE)  
  
  for(i in 1:n){
    order_final[i, ] <- album_order_fun()
    }
  
  order_final <- order_final %>%
    mutate(orderdate = orderdate,
           store.id = orderstore.id)
  
  order_final
  
  # end if
  }
# end funtion
}

```


```{r}
order_fun()
```


Now a run of multiple orders...

```{r}

m = 750


order_multi <- data.frame(artist = as.character(),
                          album = as.character(),
                          price = as.double(),
                          format = as.character(),
                          qty = as.integer(),
                          orderdate = as_date(as.character()),
                          store.id = as.character(),
                          stringsAsFactors = FALSE)  
  
  for(i in 1:m){
    order_final <- order_fun()
    order_multi <- rbind(order_multi, order_final)
  }
  
order_multi

write_csv(order_multi, "order_multi.csv")  

```


#### Summary tables

```{r}

order_multi %>%
  group_by(store.id, orderdate) %>%
  tally()


order_multi %>%
  group_by(artist) %>%
  summarise(qty = sum(qty)) %>%
  arrange(desc(qty))

```

Build a large scale summary table

```{r}

order_multi %>%
  mutate(order_price = qty * price) %>%
  group_by(artist, format) %>%
  summarise(qty = sum(qty),
            cost = sum(order_price)) %>%
  arrange(desc(qty))


order_multi %>%
  mutate(order_price = qty * price) %>%
  left_join(storelist, by = "store.id") %>%
  group_by(chain) %>%
  summarise(qty = sum(qty),
            cost = sum(order_price)) %>%
  arrange(desc(qty))

order_multi %>%
  mutate(order_price = qty * price) %>%
  left_join(storelist, by = "store.id") %>%
  group_by(region) %>%
  summarise(qty = sum(qty),
            cost = sum(order_price)) %>%
  mutate(pct_of_sales = cost / sum(cost) * 100) %>%
  arrange(desc(qty))

```



---


```{r}
order_multi %>%
  mutate(order_price = qty * price) %>%
  left_join(storelist, by = "store.id") %>%
  group_by(region) %>%
  summarise(qty = sum(qty),
            sales = sum(order_price)) %>%
  mutate(pct_of_sales = sales / sum(sales) * 100) %>%
  arrange(desc(qty)) %>% 
#
ggplot(mapping = aes(x = reorder(region, -sales), y = sales)) +
  geom_point(size = 5) + 
  geom_segment(aes(xend = region), yend = 0, colour = "black", size = 2) +
  ylim(0, 60000)

#ggsave("sales_region.png")

```




## References

The GitHub page with the data for Walt Hickey's article is available through [GitHub](https://github.com/fivethirtyeight/data/tree/master/classic-rock)


